{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flex GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data and split training and testing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt</th>\n",
       "      <th>has_template</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21016</th>\n",
       "      <td>Theory Z is a name applied to two distinctly d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24880</th>\n",
       "      <td>Bettystown (), previously known as Betaghstown...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15447</th>\n",
       "      <td>Goop has faced severe criticism for promoting ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11240</th>\n",
       "      <td>Track Listing  Steve Eaves's Myspace Page</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14332</th>\n",
       "      <td>Reality-based community is an informal term in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19602</th>\n",
       "      <td>Jim Bowen (born in Heswall, Cheshire, England ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19076</th>\n",
       "      <td>Bell-bottoms (or flares) are a style of pants ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14487</th>\n",
       "      <td>Tunceli Province (, , ), formerly Dersim Provi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>right|thumb|200px|A live frog is magnetically ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13233</th>\n",
       "      <td>Nikki Araguz (born Justin Graham Purdue, June ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24988 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     txt  has_template\n",
       "21016  Theory Z is a name applied to two distinctly d...             0\n",
       "24880  Bettystown (), previously known as Betaghstown...             0\n",
       "15447  Goop has faced severe criticism for promoting ...             1\n",
       "11240          Track Listing  Steve Eaves's Myspace Page             1\n",
       "14332  Reality-based community is an informal term in...             1\n",
       "...                                                  ...           ...\n",
       "19602  Jim Bowen (born in Heswall, Cheshire, England ...             0\n",
       "19076  Bell-bottoms (or flares) are a style of pants ...             0\n",
       "14487  Tunceli Province (, , ), formerly Dersim Provi...             1\n",
       "202    right|thumb|200px|A live frog is magnetically ...             1\n",
       "13233  Nikki Araguz (born Justin Graham Purdue, June ...             1\n",
       "\n",
       "[24988 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\email\\OneDrive\\Documents\\Python\\quora_classifier\\data\\original.csv\")\n",
    "data = data.loc[:, ['txt','has_template']]\n",
    "data, test = train_test_split(data, test_size = 0.2, stratify=data['has_template'], shuffle=True, random_state= 999)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequences(Dataset):\n",
    "    def __init__(self, data) -> None:\n",
    "        self.data = data.reset_index(drop = True)\n",
    "        self.model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        # return the ith sample's list of word counts and label\n",
    "        return self.model.encode(self.data.loc[i, 'txt']), self.data.has_template[i]\n",
    "    \n",
    "    def __len__(self):\n",
    "        # return number of samples\n",
    "        return self.data.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Sequences(data)\n",
    "train_loader = DataLoader(dataset, batch_size = 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BagOfWordsClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden1, hidden2, hidden3):\n",
    "        super(BagOfWordsClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(vocab_size, hidden1)\n",
    "        self.fc2 = nn.Linear(hidden1, hidden2)\n",
    "        self.fc3 = nn.Linear(hidden2, hidden3)\n",
    "        self.fc4 = nn.Linear(hidden3, 1)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        x = F.relu(self.fc1(inputs.squeeze(1).float()))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return self.fc4(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BagOfWordsClassifier(768, 128, 64, 8)\n",
    "model.to(device)\n",
    "next(model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set loss, optimization functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam([p for p in model.parameters() if p.requires_grad], lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop():\n",
    "    for epoch in range(3):\n",
    "\n",
    "        train_losses = []\n",
    "        progress_bar = tqdm(train_loader, leave=False)\n",
    "        losses = []\n",
    "        accuracies = []\n",
    "        total = 0\n",
    "        \n",
    "        for txt, has_template in progress_bar:\n",
    "            txt = txt.to(device)\n",
    "            has_template = has_template.to(device)\n",
    "\n",
    "            model.zero_grad()\n",
    "\n",
    "            output = model(txt)\n",
    "            loss = criterion(output.squeeze(), has_template.float())\n",
    "            loss.backward()\n",
    "            # nn.utils.clip_grad_norm_(model.parameters(), 3) # What?\n",
    "            optimizer.step()\n",
    "\n",
    "            accuracy = torch.eq((torch.sigmoid(output) >= 0.5).squeeze(), has_template).sum().item() / has_template.shape[0]\n",
    "            accuracies.append(accuracy)\n",
    "            losses.append(loss.item())\n",
    "            total += 1\n",
    "            \n",
    "            progress_bar.set_description(f'Loss: {loss.item():.3f}, Train Accuracy: {accuracy:.3f}')\n",
    "            \n",
    "        epoch_loss = sum(losses) / total\n",
    "        epoch_accuracy = sum(accuracies) / total\n",
    "        train_losses.append(epoch_loss)\n",
    "            \n",
    "        tqdm.write(f'Epoch #{epoch + 1}\\tLoss: {epoch_loss:.3f}\\tAccuracy: {epoch_accuracy:.3f}')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dbe06fb8eeb489ba5f9d0551941ab9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1\tLoss: 0.668\tAccuracy: 0.551\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b58eaeba33694e7b861e54b0b72fb941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #2\tLoss: 0.666\tAccuracy: 0.552\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7129bc0e0b18480bb42bd319bccab0bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #3\tLoss: 0.665\tAccuracy: 0.558\n"
     ]
    }
   ],
   "source": [
    "training_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop():\n",
    "    accuracies = []\n",
    "    test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    test_dataset = Sequences(test)\n",
    "    test_loader = DataLoader(test_dataset, batch_size = 512)\n",
    "\n",
    "    progress_bar = tqdm(test_loader, leave=False)\n",
    "    test_model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "    total = 0\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    for txt, has_template in progress_bar:\n",
    "        txt, has_template = txt.to(device), has_template.to(device)\n",
    "        output = model(txt)\n",
    "        # prediction = round(torch.sigmoid(model(torch.LongTensor(test_model.encode(test.loc[i, 'txt']), test.has_template[i]).to(device))).item())\n",
    "        accuracy = torch.eq((torch.sigmoid(output) >= 0.5).squeeze(), has_template).sum().item() / has_template.shape[0]\n",
    "        accuracies.append(accuracy)\n",
    "        total = total + 1\n",
    "        predictions = predictions + torch.round(torch.sigmoid(output).squeeze()).tolist()\n",
    "\n",
    "    # return sum(accuracies) / total\n",
    "    return predictions\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d4086955990453aba95b62af65c700f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = test_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"BERT_wikipedia_file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BagOfWordsClassifier(len(dataset.token2idx), 128, 64, 8)\n",
    "model.load_state_dict(torch.load(r'C:\\Users\\email\\OneDrive\\Documents\\Python\\quora_classifier\\models\\bow3_6\\epoch_1_2022-08-16__08-05-11'))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(torch.sigmoid(model(torch.tensor(test_model.encode(\"I am gay boy and I love my cousin (boy). He is sexy, but I dont know what to do. He is hot\")).reshape([768,1]).to(device))).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5389597719971848"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(test['has_template'], predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f96c0a065a6f038b4d81e02ec5e62503dd3b71442db074018719e130d8db16de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
